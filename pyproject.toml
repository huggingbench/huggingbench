[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"

[project]
name = "hugging-bench-project"
description = "Benchmark hugginfface models in different formats such and configs in Triton Inference Server"
readme = "README.md"
requires-python = ">=3.9"
keywords = ["Hugging Face", "Performance Benchmark", "ML model"]
license = {text = "Apache 2.0 License"}
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: Apache Software License",
]
dependencies = [
        'tritonclient[all]==2.33.0',
        'prometheus-client==0.16.0',
        'docker==6.1.2',
        'datasets==2.12.0',
        'transformers==4.29.2',
        'torchvision==0.15.2',
        'numpy==1.24.3',  
        'onnx==1.14.0',
        'matplotlib==3.7.1',
        'colored',
        'polygraphy==0.47.1',
]
dynamic = ["version"]

[project.optional-dependencies]
dev = [
  'black',
  'isort',
  'autoflake',
]

tests = [
  'pytest==7.3.2',
]

[project.scripts]
runbench = "server.main:mlperf"

[tool.setuptools.packages.find]
where = ["src"]
include = ["client", "server"]
namespaces = false

[tool.black]
line-length = 120
target-version = ['py39']

[tool.isort]
profile = "black"
                                                                                                    